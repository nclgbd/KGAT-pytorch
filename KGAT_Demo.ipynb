{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Nicole Guo**\n",
    "\n",
    "**June 12th, 2022**\n",
    "\n",
    "# KGAT Demo\n",
    "\n",
    "Since the was no available online implementation of KGAT-SR, it was decided that I would instead attempt to reproduce KGAT, and demonstrate how to run the program within this notebook. This code is not the exact implementation of KGAT that the authors created. Rather, this is a re-implementation using PyTorch. The original code for the paper can be found [here](https://github.com/xiangwang1223/knowledge_graph_attention_network) and the PyTorch implementation of which this project is forked from can be found [here](https://github.com/LunaBlack/KGAT-pytorch).\n",
    "\n",
    "To get this program to run, I simply forked the [GitHub repository](https://github.com/LunaBlack/KGAT-pytorch), and created an Anaconda environment to use as a kernel. The required packages can likewise be seen in the `README.md` file [here](https://github.com/LunaBlack/KGAT-pytorch/blob/master/README.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code breakdown\n",
    "The main files I will be referring to and breaking down are located in [KGAT.py](./model/KGAT.py) and [main_kgat.py](./main_kgat.py). \n",
    "\n",
    "## `KGAT.py`\n",
    "![](media/illustration_kgat_model.PNG)\n",
    "\n",
    "The `KGAT.py` file contains the definition of the model itself using references from the paper as needed. This can be found throughout the file itself. It is broken down into two main classes: the `Aggregator` class and the `KGAT` class. I'll start by breaking down the `KGAT` class\n",
    "\n",
    "### `KGAT` class\n",
    "The `KGAT` class serves as the primary module for implementing the different equations relating to the paper. Each function is associated with it's corresponding equation in the original paper.\n",
    "- **`calc_cf_embeddings`** - this refers to section 3.3, and works \"to concatenate the representations at each step into a single vector\" (5). It corresponds to Equation 11.\n",
    "\n",
    "```python\n",
    "    def calc_cf_embeddings(self):\n",
    "        ego_embed = self.entity_user_embed.weight\n",
    "        all_embed = [ego_embed]\n",
    "\n",
    "        for idx, layer in enumerate(self.aggregator_layers):\n",
    "            ego_embed = layer(ego_embed, self.A_in)\n",
    "            norm_embed = F.normalize(ego_embed, p=2, dim=1)\n",
    "            all_embed.append(norm_embed)\n",
    "\n",
    "        # Equation (11)\n",
    "        all_embed = torch.cat(all_embed, dim=1)         # (n_users + n_entities, concat_dim)\n",
    "        return all_embed\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "- **`calc_kg_loss`** - this function calculates the loss for the Knowledge graph (known as the \"plausibiliy score\") as defined in Equation 1 and Equation 2. Using the TransR method, the relative order between valid triplets and broken ones are learned during the training of the model and calculates a pairwise ranking loss (3-4), which is one half of the total loss of the GNN.\n",
    "\n",
    "```python\n",
    "    def calc_kg_loss(self, h, r, pos_t, neg_t):\n",
    "        \"\"\"\n",
    "        h:      (kg_batch_size)\n",
    "        r:      (kg_batch_size)\n",
    "        pos_t:  (kg_batch_size)\n",
    "        neg_t:  (kg_batch_size)\n",
    "        \"\"\"\n",
    "        r_embed = self.relation_embed(r)                                                # (kg_batch_size, relation_dim)\n",
    "        W_r = self.trans_M[r]                                                           # (kg_batch_size, embed_dim, relation_dim)\n",
    "\n",
    "        h_embed = self.entity_user_embed(h)                                             # (kg_batch_size, embed_dim)\n",
    "        pos_t_embed = self.entity_user_embed(pos_t)                                     # (kg_batch_size, embed_dim)\n",
    "        neg_t_embed = self.entity_user_embed(neg_t)                                     # (kg_batch_size, embed_dim)\n",
    "\n",
    "        r_mul_h = torch.bmm(h_embed.unsqueeze(1), W_r).squeeze(1)                       # (kg_batch_size, relation_dim)\n",
    "        r_mul_pos_t = torch.bmm(pos_t_embed.unsqueeze(1), W_r).squeeze(1)               # (kg_batch_size, relation_dim)\n",
    "        r_mul_neg_t = torch.bmm(neg_t_embed.unsqueeze(1), W_r).squeeze(1)               # (kg_batch_size, relation_dim)\n",
    "\n",
    "        # Equation (1)\n",
    "        pos_score = torch.sum(torch.pow(r_mul_h + r_embed - r_mul_pos_t, 2), dim=1)     # (kg_batch_size)\n",
    "        neg_score = torch.sum(torch.pow(r_mul_h + r_embed - r_mul_neg_t, 2), dim=1)     # (kg_batch_size)\n",
    "\n",
    "        # Equation (2)\n",
    "        # kg_loss = F.softplus(pos_score - neg_score)\n",
    "        kg_loss = (-1.0) * F.logsigmoid(neg_score - pos_score)\n",
    "        kg_loss = torch.mean(kg_loss)\n",
    "\n",
    "        l2_loss = _L2_loss_mean(r_mul_h) + _L2_loss_mean(r_embed) + _L2_loss_mean(r_mul_pos_t) + _L2_loss_mean(r_mul_neg_t)\n",
    "        loss = kg_loss + self.kg_l2loss_lambda * l2_loss\n",
    "        return loss\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "- **`calc_cf_loss`** - this function calculates the collaberative filtering (CF) loss as defined in Equation 13. This is the other half of the total oss of the GNN.\n",
    "\n",
    "```python\n",
    "    def calc_cf_loss(self, user_ids, item_pos_ids, item_neg_ids):\n",
    "        \"\"\"\n",
    "        user_ids:       (cf_batch_size)\n",
    "        item_pos_ids:   (cf_batch_size)\n",
    "        item_neg_ids:   (cf_batch_size)\n",
    "        \"\"\"\n",
    "        all_embed = self.calc_cf_embeddings()                       # (n_users + n_entities, concat_dim)\n",
    "        user_embed = all_embed[user_ids]                            # (cf_batch_size, concat_dim)\n",
    "        item_pos_embed = all_embed[item_pos_ids]                    # (cf_batch_size, concat_dim)\n",
    "        item_neg_embed = all_embed[item_neg_ids]                    # (cf_batch_size, concat_dim)\n",
    "\n",
    "        # Equation (12)\n",
    "        pos_score = torch.sum(user_embed * item_pos_embed, dim=1)   # (cf_batch_size)\n",
    "        neg_score = torch.sum(user_embed * item_neg_embed, dim=1)   # (cf_batch_size)\n",
    "\n",
    "        # Equation (13)\n",
    "        # cf_loss = F.softplus(neg_score - pos_score)\n",
    "        cf_loss = (-1.0) * F.logsigmoid(pos_score - neg_score)\n",
    "        cf_loss = torch.mean(cf_loss)\n",
    "\n",
    "        l2_loss = _L2_loss_mean(user_embed) + _L2_loss_mean(item_pos_embed) + _L2_loss_mean(item_neg_embed)\n",
    "        loss = cf_loss + self.cf_l2loss_lambda * l2_loss\n",
    "        return loss\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "- **`update_attention_batch`** - this refers to the **Knowledge-aware attention mechanism**, and corresponds to Equation 4. This \"makes the attention score dependent on the distance between head and tail entity in the specific relation space allowing for more information to be propagated between closer entities\" (4).\n",
    "\n",
    "```python\n",
    "    def update_attention_batch(self, h_list, t_list, r_idx):\n",
    "        r_embed = self.relation_embed.weight[r_idx]\n",
    "        W_r = self.trans_M[r_idx]\n",
    "\n",
    "        h_embed = self.entity_user_embed.weight[h_list]\n",
    "        t_embed = self.entity_user_embed.weight[t_list]\n",
    "\n",
    "        # Equation (4)\n",
    "        r_mul_h = torch.matmul(h_embed, W_r)\n",
    "        r_mul_t = torch.matmul(t_embed, W_r)\n",
    "        v_list = torch.sum(r_mul_t * torch.tanh(r_mul_h + r_embed), dim=1)\n",
    "        return v_list\n",
    "\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "- **`update_attention`** - this function updates the entire network by using normalized weights across all triplets connected to the head node using the SoftMax function. It corresponds to Equation 5.\n",
    "\n",
    "```python\n",
    "    def update_attention(self, h_list, t_list, r_list, relations):\n",
    "        device = self.A_in.device\n",
    "\n",
    "        rows = []\n",
    "        cols = []\n",
    "        values = []\n",
    "\n",
    "        for r_idx in relations:\n",
    "            index_list = torch.where(r_list == r_idx)\n",
    "            batch_h_list = h_list[index_list]\n",
    "            batch_t_list = t_list[index_list]\n",
    "\n",
    "            batch_v_list = self.update_attention_batch(batch_h_list, batch_t_list, r_idx)\n",
    "            rows.append(batch_h_list)\n",
    "            cols.append(batch_t_list)\n",
    "            values.append(batch_v_list)\n",
    "\n",
    "        rows = torch.cat(rows)\n",
    "        cols = torch.cat(cols)\n",
    "        values = torch.cat(values)\n",
    "\n",
    "        indices = torch.stack([rows, cols])\n",
    "        shape = self.A_in.shape\n",
    "        A_in = torch.sparse.FloatTensor(indices, values, torch.Size(shape))\n",
    "\n",
    "        # Equation (5)\n",
    "        A_in = torch.sparse.softmax(A_in.cpu(), dim=1)\n",
    "        self.A_in.data = A_in.to(device)\n",
    "```\n",
    "\n",
    "\n",
    "- **`calc_score`** - This is the prediction function, which uses the inner product of user and item representations to form a prediction (5). This corresponds to Equation 12. \n",
    "\n",
    "```python\n",
    "    def calc_score(self, user_ids, item_ids):\n",
    "        \"\"\"\n",
    "        user_ids:  (n_users)\n",
    "        item_ids:  (n_items)\n",
    "        \"\"\"\n",
    "        all_embed = self.calc_cf_embeddings()           # (n_users + n_entities, concat_dim)\n",
    "        user_embed = all_embed[user_ids]                # (n_users, concat_dim)\n",
    "        item_embed = all_embed[item_ids]                # (n_items, concat_dim)\n",
    "\n",
    "        # Equation (12)\n",
    "        cf_score = torch.matmul(user_embed, item_embed.transpose(0, 1))    # (n_users, n_items)\n",
    "        return cf_score\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "### `Aggregator` class\n",
    "The `Aggregator` class corresponds to section 3.2 in the original KGAT paper. This section discusses three different kinds of aggregators, the **GCN Aggregator** (Equation 6), **Bi-Interation Aggregator** (Equation 8), and **GraphSage Aggregator** (Equation 7). Likewise, the different `aggregator_type`'s that are available for the user to use is `gcn`, `bi-interaction`, and `graphsage`, which correspond to the each equation respectively. \n",
    "\n",
    "```python\n",
    "def __init__(self, in_dim, out_dim, dropout, aggregator_type):\n",
    "    super(Aggregator, self).__init__()\n",
    "    self.in_dim = in_dim\n",
    "    self.out_dim = out_dim\n",
    "    self.dropout = dropout\n",
    "    self.aggregator_type = aggregator_type\n",
    "\n",
    "    self.message_dropout = nn.Dropout(dropout)\n",
    "    self.activation = nn.LeakyReLU()\n",
    "\n",
    "    if self.aggregator_type == 'gcn':\n",
    "        self.linear = nn.Linear(self.in_dim, self.out_dim)       # W in Equation (6)\n",
    "        nn.init.xavier_uniform_(self.linear.weight)\n",
    "\n",
    "    elif self.aggregator_type == 'graphsage':\n",
    "        self.linear = nn.Linear(self.in_dim * 2, self.out_dim)   # W in Equation (7)\n",
    "        nn.init.xavier_uniform_(self.linear.weight)\n",
    "\n",
    "    elif self.aggregator_type == 'bi-interaction':\n",
    "        self.linear1 = nn.Linear(self.in_dim, self.out_dim)      # W1 in Equation (8)\n",
    "        self.linear2 = nn.Linear(self.in_dim, self.out_dim)      # W2 in Equation (8)\n",
    "        nn.init.xavier_uniform_(self.linear1.weight)\n",
    "        nn.init.xavier_uniform_(self.linear2.weight)\n",
    "\n",
    "    else:\n",
    "        raise NotImplementedError\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## `main_kgat.py`\n",
    "`main_kgat.py` serves as the training script for the KGAT model. The main functions that we will focus on is the `train` and `evaluate` functions. The **`train`** function sets up the logging functionality, loads the data, creates the model and optimizers, and then begins training. At the end of training, the best iteration of the model's weights are saved to a `.pth` file. The **`evaluate`** function calculates the metrics as defined in the paper, in addition to precision. The CF (collaborative filtering) score is also returned, to later be combined with the KG (knowledge graph) score to calculate the total loss of the KGAT model.\n",
    "\n",
    "Running this as a script is easy; running `python main_kgat.py` will train the KGAT model using the default parameters as defined in [`parser_kgat.py`](argparsers/parser_kgat.py). These parameters can be changed by adding in command line arguments. Here are all available command line parameters:\n",
    "```\n",
    "usage: main_kgat.py [-h] [--seed SEED] [--data_name [DATA_NAME]] [--data_dir [DATA_DIR]] [--use_pretrain USE_PRETRAIN] [--pretrain_embedding_dir [PRETRAIN_EMBEDDING_DIR]] [--pretrain_model_path [PRETRAIN_MODEL_PATH]]\n",
    "                    [--cf_batch_size CF_BATCH_SIZE] [--kg_batch_size KG_BATCH_SIZE] [--test_batch_size TEST_BATCH_SIZE] [--embed_dim EMBED_DIM] [--relation_dim RELATION_DIM] [--laplacian_type LAPLACIAN_TYPE]\n",
    "                    [--aggregation_type AGGREGATION_TYPE] [--conv_dim_list [CONV_DIM_LIST]] [--mess_dropout [MESS_DROPOUT]] [--kg_l2loss_lambda KG_L2LOSS_LAMBDA] [--cf_l2loss_lambda CF_L2LOSS_LAMBDA] [--lr LR] [--n_epoch N_EPOCH]\n",
    "                    [--stopping_steps STOPPING_STEPS] [--cf_print_every CF_PRINT_EVERY] [--kg_print_every KG_PRINT_EVERY] [--evaluate_every EVALUATE_EVERY] [--Ks [KS]]\n",
    "\n",
    "Run KGAT.\n",
    "\n",
    "optional arguments:\n",
    "  -h, --help            show this help message and exit\n",
    "  --seed SEED           Random seed.\n",
    "  --data_name [DATA_NAME]\n",
    "                        Choose a dataset from {yelp2018, last-fm, amazon-book}\n",
    "  --data_dir [DATA_DIR]\n",
    "                        Input data path.\n",
    "  --use_pretrain USE_PRETRAIN\n",
    "                        0: No pretrain, 1: Pretrain with the learned embeddings, 2: Pretrain with stored model.\n",
    "  --pretrain_embedding_dir [PRETRAIN_EMBEDDING_DIR]\n",
    "                        Path of learned embeddings.\n",
    "  --pretrain_model_path [PRETRAIN_MODEL_PATH]\n",
    "                        Path of stored model.\n",
    "  --cf_batch_size CF_BATCH_SIZE\n",
    "                        CF batch size.\n",
    "  --kg_batch_size KG_BATCH_SIZE\n",
    "                        KG batch size.\n",
    "  --test_batch_size TEST_BATCH_SIZE\n",
    "                        Test batch size (the user number to test every batch).\n",
    "  --embed_dim EMBED_DIM\n",
    "                        User / entity Embedding size.\n",
    "  --relation_dim RELATION_DIM\n",
    "                        Relation Embedding size.\n",
    "  --laplacian_type LAPLACIAN_TYPE\n",
    "                        Specify the type of the adjacency (laplacian) matrix from {symmetric, random-walk}.\n",
    "  --aggregation_type AGGREGATION_TYPE\n",
    "                        Specify the type of the aggregation layer from {gcn, graphsage, bi-interaction}.\n",
    "  --conv_dim_list [CONV_DIM_LIST]\n",
    "                        Output sizes of every aggregation layer.\n",
    "  --mess_dropout [MESS_DROPOUT]\n",
    "                        Dropout probability w.r.t. message dropout for each deep layer. 0: no dropout.\n",
    "  --kg_l2loss_lambda KG_L2LOSS_LAMBDA\n",
    "                        Lambda when calculating KG l2 loss.\n",
    "  --cf_l2loss_lambda CF_L2LOSS_LAMBDA\n",
    "                        Lambda when calculating CF l2 loss.\n",
    "  --lr LR               Learning rate.\n",
    "  --n_epoch N_EPOCH     Number of epoch.\n",
    "  --stopping_steps STOPPING_STEPS\n",
    "                        Number of epoch for early stopping\n",
    "  --cf_print_every CF_PRINT_EVERY\n",
    "                        Iter interval of printing CF loss.\n",
    "  --kg_print_every KG_PRINT_EVERY\n",
    "                        Iter interval of printing KG loss.\n",
    "  --evaluate_every EVALUATE_EVERY\n",
    "                        Epoch interval of evaluating CF.\n",
    "  --Ks [KS]             Calculate metric@K when evaluating.\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment description\n",
    "The original KGAT paper investigates a number of research questions thoroughly, however for this demonstration I will be attempting one problem:\n",
    "- *Is it possible to reproduce the results as presented in the paper? Additionally, how does the original paper and this PyTorch implementation look when compared with the results achieved from our local run?*\n",
    "\n",
    "To this end, tests were run using the same configuration as detailed in the paper in three different environments. The metrics compared in the paper (recall@20, ndcg@20) in addition to precision@20 were also calculated to be compared. The dataset used is [`amazon-book`](http://jmcauley.ucsd.edu/data/amazon/), as it was the only dataset for which all metrics were reported on regarding the original paper and the PyTorch implementation. A demonstration to run the program before looks like this:\n",
    "```batch\n",
    "python main_kgat.py --data_name amazon-book\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "2022-06-12 12:26:02,454 - root - INFO - Namespace(Ks='[20, 40, 60, 80, 100]', aggregation_type='bi-interaction', cf_batch_size=1024, cf_l2loss_lambda=1e-05, cf_print_every=1, conv_dim_list='[64, 32, 16]', data_dir='datasets/', data_name='amazon-book', embed_dim=64, evaluate_every=10, kg_batch_size=2048, kg_l2loss_lambda=1e-05, kg_print_every=1, laplacian_type='random-walk', lr=0.0001, mess_dropout='[0.1, 0.1, 0.1]', n_epoch=5, pretrain_embedding_dir='datasets/pretrain/', pretrain_model_path='trained_model/model.pth', relation_dim=64, save_dir='trained_model/KGAT/amazon-book/embed-dim64_relation-dim64_random-walk_bi-interaction_64-32-16_lr0.0001_pretrain1/', seed=2019, stopping_steps=10, test_batch_size=10000, use_pretrain=1)\n",
    "2022-06-12 12:29:09,670 - root - INFO - n_users:           70679\n",
    "2022-06-12 12:29:09,671 - root - INFO - n_items:           24915\n",
    "2022-06-12 12:29:09,671 - root - INFO - n_entities:        113487\n",
    "2022-06-12 12:29:09,671 - root - INFO - n_users_entities:  184166\n",
    "2022-06-12 12:29:09,671 - root - INFO - n_relations:       80\n",
    "2022-06-12 12:29:09,671 - root - INFO - n_h_list:          6420520\n",
    "2022-06-12 12:29:09,672 - root - INFO - n_t_list:          6420520\n",
    "2022-06-12 12:29:09,672 - root - INFO - n_r_list:          6420520\n",
    "2022-06-12 12:29:09,672 - root - INFO - n_cf_train:        652514\n",
    "2022-06-12 12:29:09,672 - root - INFO - n_cf_test:         193920\n",
    "2022-06-12 12:29:09,672 - root - INFO - n_kg_train:        6420520\n",
    "2022-06-12 12:29:14,953 - root - INFO - KGAT(\n",
    "  (entity_user_embed): Embedding(184166, 64)\n",
    "  (relation_embed): Embedding(80, 64)\n",
    "  (aggregator_layers): ModuleList(\n",
    "    (0): Aggregator(\n",
    "      (message_dropout): Dropout(p=0.1, inplace=False)\n",
    "      (activation): LeakyReLU(negative_slope=0.01)\n",
    "      (linear1): Linear(in_features=64, out_features=64, bias=True)\n",
    "      (linear2): Linear(in_features=64, out_features=64, bias=True)\n",
    "    )\n",
    "    (1): Aggregator(\n",
    "      (message_dropout): Dropout(p=0.1, inplace=False)\n",
    "      (activation): LeakyReLU(negative_slope=0.01)\n",
    "      (linear1): Linear(in_features=64, out_features=32, bias=True)\n",
    "      (linear2): Linear(in_features=64, out_features=32, bias=True)\n",
    "    )\n",
    "    (2): Aggregator(\n",
    "      (message_dropout): Dropout(p=0.1, inplace=False)\n",
    "      (activation): LeakyReLU(negative_slope=0.01)\n",
    "      (linear1): Linear(in_features=32, out_features=16, bias=True)\n",
    "      (linear2): Linear(in_features=32, out_features=16, bias=True)\n",
    "    )\n",
    "  )\n",
    ")\n",
    "2022-06-12 12:29:19,025 - root - INFO - CF Training: Epoch 0001 Iter 0001 / 0638 | Time 4.1s | Iter Loss 0.0285 | Iter Mean Loss 0.0285\n",
    "2022-06-12 12:29:22,951 - root - INFO - CF Training: Epoch 0001 Iter 0002 / 0638 | Time 3.9s | Iter Loss 0.0238 | Iter Mean Loss 0.0261\n",
    "2022-06-12 12:29:26,886 - root - INFO - CF Training: Epoch 0001 Iter 0003 / 0638 | Time 3.9s | Iter Loss 0.0264 | Iter Mean Loss 0.0262\n",
    ".\n",
    ".\n",
    ".\n",
    "2022-06-12 16:41:43,259 - root - INFO - KG Training: Epoch 0005 Iter 3130 / 3136 | Time 0.2s | Iter Loss 0.0071 | Iter Mean Loss 0.0177\n",
    "2022-06-12 16:41:43,449 - root - INFO - KG Training: Epoch 0005 Iter 3131 / 3136 | Time 0.2s | Iter Loss 0.0098 | Iter Mean Loss 0.0177\n",
    "2022-06-12 16:41:43,622 - root - INFO - KG Training: Epoch 0005 Iter 3132 / 3136 | Time 0.2s | Iter Loss 0.0134 | Iter Mean Loss 0.0177\n",
    "2022-06-12 16:41:43,829 - root - INFO - KG Training: Epoch 0005 Iter 3133 / 3136 | Time 0.2s | Iter Loss 0.0186 | Iter Mean Loss 0.0177\n",
    "2022-06-12 16:41:44,011 - root - INFO - KG Training: Epoch 0005 Iter 3134 / 3136 | Time 0.2s | Iter Loss 0.0118 | Iter Mean Loss 0.0177\n",
    "2022-06-12 16:41:44,204 - root - INFO - KG Training: Epoch 0005 Iter 3135 / 3136 | Time 0.2s | Iter Loss 0.0148 | Iter Mean Loss 0.0177\n",
    "2022-06-12 16:41:44,394 - root - INFO - KG Training: Epoch 0005 Iter 3136 / 3136 | Time 0.2s | Iter Loss 0.0194 | Iter Mean Loss 0.0177\n",
    "2022-06-12 16:41:44,394 - root - INFO - KG Training: Epoch 0005 Total Iter 3136 | Total Time 567.6s | Iter Mean Loss 0.0177\n",
    "2022-06-12 16:41:47,868 - root - INFO - Update Attention: Epoch 0005 | Total Time 3.5s\n",
    "2022-06-12 16:41:47,868 - root - INFO - CF + KG Training: Epoch 0005 | Total Time 2990.8s\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results\n",
    "The results weren't able to be completely reconstructed, however similar results were attained. After running the line above, a `.tsv` file is created storing the metric results for the entire run, using the best iteration of the model. I retrieve these results and display them below:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>epoch_idx</th>\n",
       "      <th>precision@20</th>\n",
       "      <th>recall@20</th>\n",
       "      <th>ndcg@20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.0</td>\n",
       "      <td>0.013484</td>\n",
       "      <td>0.127648</td>\n",
       "      <td>0.067181</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   epoch_idx  precision@20  recall@20   ndcg@20\n",
       "0        5.0      0.013484   0.127648  0.067181"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kgat_amazon_filepath = \"trained_model/KGAT/amazon-book/embed-dim64_relation-dim64_random-walk_bi-interaction_64-32-16_lr0.0001_pretrain1/metrics.tsv\"\n",
    "kgat_amazon_df = pd.read_csv(kgat_amazon_filepath, sep=\"\\t\")\n",
    "kgat_amazon_paper_metrics = [\"epoch_idx\", \"precision@20\", \"recall@20\", \"ndcg@20\"]\n",
    "kgat_amazon_df = kgat_amazon_df[kgat_amazon_paper_metrics]\n",
    "kgat_amazon_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That would result in this table breakdown:\n",
    "\n",
    "| Implementation                    | Best Epoch  | Precision@20  | Recall@20 | NDCG@20   |\n",
    "| --------------------------------- |-------------|---------------|-----------|-----------|\n",
    "| Orig. Paper Implementation        |      /      |       /       |   0.1489  |  0.1006   |\n",
    "| PyTorch  Implementation           |     280     |    0.0150     |   0.1440  |  0.0766   |\n",
    "| Ours Re-implementation            |      5      |    0.0135     |   0.1276  |  0.0672   |\n",
    "\n",
    "Being that our re-implementation works off of a pretrained model, seeing such good results despite having only 5 epochs to train makes sense. We can also see that the results are not perfectly aligned, however it seems clear that at a foundational level, this paper and the test environment is able to be reproduced."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Future work\n",
    "As this particular repository was incredibly flexible for different kinds of training configurations, I would have liked to explore that more. I specifically wanted to look at RQ2 from the paper, and focus on the different kinds of aggregation types as well as the different laplacian types. With the help of `wandb`, it would have been nice to run a grid search (as they did in the paper) using different configurations with the help of a VM as supplied by the univeristy. Oftne conducting a grid search with these two arguments would still require quite a bit of computation power, and thus for time and resource purposes, this was not explored in the notebook. This would have been helpful to do as this invesigation of parameters was an experiment done within the paper, and being able to recreate it in this environment would have been a fun addition to the assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References\n",
    "- *Wang, X., He, X., Cao, Y., Liu, M., & Chua, T.-S. (2019a). KGAT. Proceedings of the 25th ACM SIGKDD International Conference on Knowledge Discovery Data Mining. doi:10.1145/3292500.3330989*\n",
    "\n",
    "- *Lin, Y., Liu, Z., Sun, M., Liu, Y., & Zhu, X. (2015). Learning Entity and Relation Embeddings for Knowledge Graph Completion. Proceedings of the Twenty-Ninth AAAI Conference on Artificial Intelligence, 2181–2187. Austin, Texas: AAAI Press.*\n",
    "\n",
    "- *Wang, X., He, X., Cao, Y., Liu, M., & Chua, T.-S. (2019b). KGAT: Knowledge Graph Attention Network for Recommendation. KDD, 950–958.*\n",
    "\n",
    "- *Zhao, W. X., He, G., Yang, K., Dou, H.-J., Huang, J., Ouyang, S., & Wen, J.-R. (2019). KB4Rec: A Data Set for Linking Knowledge Bases with Recommender Systems. Data Intelligence, 1(2), 121–136. doi:10.1162/dint_a_00008*\n",
    "\n",
    "- *Huang, J., Zhao, W. X., Dou, H.-J., Wen, J.-R., & Chang, E. Y. (2018). Improving Sequential Recommendation with Knowledge-Enhanced Memory Networks. The 41st International ACM SIGIR Conference on Research & Development in Information Retrieval, SIGIR 2018, Ann Arbor, MI, USA, July 08-12, 2018, 505–514. doi:10.1145/3209978.3210017*\n",
    "\n",
    "- *Zhao, W. X., Dou, H.-J., Zhao, Y., Dong, D., & Wen, J.-R. (2019). Neural Network Based Popularity Prediction by Linking Online Content with Knowledge Bases. Advances in Knowledge Discovery and Data Mining - 23rd Pacific-Asia Conference, PAKDD 2019, Macau, China, April 14-17, 2019, Proceedings, Part II, 16–28. doi:10.1007/978-3-030-16145-3_2*\n",
    "\n",
    "- *Mining Implicit Entity Preference from User-Item Interaction Data for Knowledge Graph Completion via Adversarial Learning. (2020). Proceedings of The Web Conference.*"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "759119ed9d539a610393f7447b26ef363725b13b2078354d9d855b97d78b4fc5"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 ('kgat-pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
