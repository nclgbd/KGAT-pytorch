{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# KGAT Demo\n",
    "Since the was no available online implementation of KGAT-SR, it was decided that I would instead publish KGAT, and demonstrate how to run the program within this notebook.\n",
    "\n",
    "This notebook will be laid out as follows:\n",
    "* Results for the `amazon-book` dataset\n",
    "* Results for the `last-fm` dataset\n",
    "* Results for the `yelp2018` dataset\n",
    "\n",
    "Luckily, the `README.md` was very informative on how to get the program to run properly, as well as listing any relevant dependencies. To get this program to run, I simply cloned the [GitHub repository](https://github.com/LunaBlack/KGAT-pytorch), and created an Anaconda environment to use as a kernel. The required packages can likewise be seen in the `README.md` file [here](https://github.com/LunaBlack/KGAT-pytorch/blob/master/README.md)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results for the `amazon-book` dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python main_kgat.py --data_name amazon-book"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "2022-05-02 04:28:16,216 - root - INFO - KG Training: Epoch 0030 Iter 3115 / 3136 | Time 0.2s | Iter Loss 0.0012 | Iter Mean Loss 0.0020\n",
    "2022-05-02 04:28:16,484 - root - INFO - KG Training: Epoch 0030 Iter 3116 / 3136 | Time 0.3s | Iter Loss 0.0032 | Iter Mean Loss 0.0020\n",
    "2022-05-02 04:28:16,726 - root - INFO - KG Training: Epoch 0030 Iter 3117 / 3136 | Time 0.2s | Iter Loss 0.0022 | Iter Mean Loss 0.0020\n",
    "2022-05-02 04:28:16,994 - root - INFO - KG Training: Epoch 0030 Iter 3118 / 3136 | Time 0.3s | Iter Loss 0.0020 | Iter Mean Loss 0.0020\n",
    "2022-05-02 04:28:17,226 - root - INFO - KG Training: Epoch 0030 Iter 3119 / 3136 | Time 0.2s | Iter Loss 0.0014 | Iter Mean Loss 0.0020\n",
    "2022-05-02 04:28:17,464 - root - INFO - KG Training: Epoch 0030 Iter 3120 / 3136 | Time 0.2s | Iter Loss 0.0016 | Iter Mean Loss 0.0020\n",
    "2022-05-02 04:28:17,697 - root - INFO - KG Training: Epoch 0030 Iter 3121 / 3136 | Time 0.2s | Iter Loss 0.0013 | Iter Mean Loss 0.0020\n",
    "2022-05-02 04:28:17,926 - root - INFO - KG Training: Epoch 0030 Iter 3122 / 3136 | Time 0.2s | Iter Loss 0.0019 | Iter Mean Loss 0.0020\n",
    "2022-05-02 04:28:18,176 - root - INFO - KG Training: Epoch 0030 Iter 3123 / 3136 | Time 0.3s | Iter Loss 0.0020 | Iter Mean Loss 0.0020\n",
    "2022-05-02 04:28:18,517 - root - INFO - KG Training: Epoch 0030 Iter 3124 / 3136 | Time 0.3s | Iter Loss 0.0025 | Iter Mean Loss 0.0020\n",
    "2022-05-02 04:28:18,762 - root - INFO - KG Training: Epoch 0030 Iter 3125 / 3136 | Time 0.2s | Iter Loss 0.0004 | Iter Mean Loss 0.0020\n",
    "2022-05-02 04:28:19,037 - root - INFO - KG Training: Epoch 0030 Iter 3126 / 3136 | Time 0.3s | Iter Loss 0.0010 | Iter Mean Loss 0.0020\n",
    "2022-05-02 04:28:19,285 - root - INFO - KG Training: Epoch 0030 Iter 3127 / 3136 | Time 0.2s | Iter Loss 0.0028 | Iter Mean Loss 0.0020\n",
    "2022-05-02 04:28:19,566 - root - INFO - KG Training: Epoch 0030 Iter 3128 / 3136 | Time 0.3s | Iter Loss 0.0024 | Iter Mean Loss 0.0020\n",
    "2022-05-02 04:28:19,894 - root - INFO - KG Training: Epoch 0030 Iter 3129 / 3136 | Time 0.3s | Iter Loss 0.0047 | Iter Mean Loss 0.0020\n",
    "2022-05-02 04:28:20,166 - root - INFO - KG Training: Epoch 0030 Iter 3130 / 3136 | Time 0.3s | Iter Loss 0.0027 | Iter Mean Loss 0.0020\n",
    "2022-05-02 04:28:20,432 - root - INFO - KG Training: Epoch 0030 Iter 3131 / 3136 | Time 0.3s | Iter Loss 0.0016 | Iter Mean Loss 0.0020\n",
    "2022-05-02 04:28:20,658 - root - INFO - KG Training: Epoch 0030 Iter 3132 / 3136 | Time 0.2s | Iter Loss 0.0017 | Iter Mean Loss 0.0020\n",
    "2022-05-02 04:28:20,938 - root - INFO - KG Training: Epoch 0030 Iter 3133 / 3136 | Time 0.3s | Iter Loss 0.0011 | Iter Mean Loss 0.0020\n",
    "2022-05-02 04:28:21,197 - root - INFO - KG Training: Epoch 0030 Iter 3134 / 3136 | Time 0.3s | Iter Loss 0.0029 | Iter Mean Loss 0.0020\n",
    "2022-05-02 04:28:21,450 - root - INFO - KG Training: Epoch 0030 Iter 3135 / 3136 | Time 0.3s | Iter Loss 0.0021 | Iter Mean Loss 0.0020\n",
    "2022-05-02 04:28:21,674 - root - INFO - KG Training: Epoch 0030 Iter 3136 / 3136 | Time 0.2s | Iter Loss 0.0020 | Iter Mean Loss 0.0020\n",
    "2022-05-02 04:28:21,674 - root - INFO - KG Training: Epoch 0030 Total Iter 3136 | Total Time 818.2s | Iter Mean Loss 0.0020\n",
    "2022-05-02 04:28:27,322 - root - INFO - Update Attention: Epoch 0030 | Total Time 5.6s\n",
    "2022-05-02 04:28:27,322 - root - INFO - CF + KG Training: Epoch 0030 | Total Time 3871.4s\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results for the `last-fm` dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python main_kgat.py --data_name last-fm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "2022-05-04 16:57:03,782 - root - INFO - KG Training: Epoch 0010 Iter 1696 / 1713 | Time 0.1s | Iter Loss 0.0663 | Iter Mean Loss 0.0585\n",
    "2022-05-04 16:57:03,932 - root - INFO - KG Training: Epoch 0010 Iter 1697 / 1713 | Time 0.1s | Iter Loss 0.0584 | Iter Mean Loss 0.0585\n",
    "2022-05-04 16:57:04,084 - root - INFO - KG Training: Epoch 0010 Iter 1698 / 1713 | Time 0.2s | Iter Loss 0.0585 | Iter Mean Loss 0.0585\n",
    "2022-05-04 16:57:04,242 - root - INFO - KG Training: Epoch 0010 Iter 1699 / 1713 | Time 0.2s | Iter Loss 0.0516 | Iter Mean Loss 0.0585\n",
    "2022-05-04 16:57:04,403 - root - INFO - KG Training: Epoch 0010 Iter 1700 / 1713 | Time 0.2s | Iter Loss 0.0520 | Iter Mean Loss 0.0585\n",
    "2022-05-04 16:57:04,562 - root - INFO - KG Training: Epoch 0010 Iter 1701 / 1713 | Time 0.2s | Iter Loss 0.0602 | Iter Mean Loss 0.0585\n",
    "2022-05-04 16:57:04,710 - root - INFO - KG Training: Epoch 0010 Iter 1702 / 1713 | Time 0.1s | Iter Loss 0.0468 | Iter Mean Loss 0.0585\n",
    "2022-05-04 16:57:04,858 - root - INFO - KG Training: Epoch 0010 Iter 1703 / 1713 | Time 0.1s | Iter Loss 0.0599 | Iter Mean Loss 0.0585\n",
    "2022-05-04 16:57:05,006 - root - INFO - KG Training: Epoch 0010 Iter 1704 / 1713 | Time 0.1s | Iter Loss 0.0512 | Iter Mean Loss 0.0585\n",
    "2022-05-04 16:57:05,161 - root - INFO - KG Training: Epoch 0010 Iter 1705 / 1713 | Time 0.2s | Iter Loss 0.0486 | Iter Mean Loss 0.0585\n",
    "2022-05-04 16:57:05,314 - root - INFO - KG Training: Epoch 0010 Iter 1706 / 1713 | Time 0.2s | Iter Loss 0.0516 | Iter Mean Loss 0.0585\n",
    "2022-05-04 16:57:05,459 - root - INFO - KG Training: Epoch 0010 Iter 1707 / 1713 | Time 0.1s | Iter Loss 0.0526 | Iter Mean Loss 0.0585\n",
    "2022-05-04 16:57:05,602 - root - INFO - KG Training: Epoch 0010 Iter 1708 / 1713 | Time 0.1s | Iter Loss 0.0581 | Iter Mean Loss 0.0585\n",
    "2022-05-04 16:57:05,745 - root - INFO - KG Training: Epoch 0010 Iter 1709 / 1713 | Time 0.1s | Iter Loss 0.0486 | Iter Mean Loss 0.0585\n",
    "2022-05-04 16:57:05,888 - root - INFO - KG Training: Epoch 0010 Iter 1710 / 1713 | Time 0.1s | Iter Loss 0.0500 | Iter Mean Loss 0.0585\n",
    "2022-05-04 16:57:06,036 - root - INFO - KG Training: Epoch 0010 Iter 1711 / 1713 | Time 0.1s | Iter Loss 0.0586 | Iter Mean Loss 0.0585\n",
    "2022-05-04 16:57:06,179 - root - INFO - KG Training: Epoch 0010 Iter 1712 / 1713 | Time 0.1s | Iter Loss 0.0491 | Iter Mean Loss 0.0585\n",
    "2022-05-04 16:57:06,324 - root - INFO - KG Training: Epoch 0010 Iter 1713 / 1713 | Time 0.1s | Iter Loss 0.0507 | Iter Mean Loss 0.0585\n",
    "2022-05-04 16:57:06,324 - root - INFO - KG Training: Epoch 0010 Total Iter 1713 | Total Time 257.4s | Iter Mean Loss 0.0585\n",
    "2022-05-04 16:57:08,753 - root - INFO - Update Attention: Epoch 0010 | Total Time 2.4s\n",
    "2022-05-04 16:57:08,753 - root - INFO - CF + KG Training: Epoch 0010 | Total Time 5315.5s\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results for the `yelp2018` dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python main_kgat.py --data_name yelp2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "2022-05-02 16:12:53,054 - root - INFO - KG Training: Epoch 0010 Iter 2702 / 2719 | Time 0.2s | Iter Loss 0.0075 | Iter Mean Loss 0.0084\n",
    "2022-05-02 16:12:53,252 - root - INFO - KG Training: Epoch 0010 Iter 2703 / 2719 | Time 0.2s | Iter Loss 0.0096 | Iter Mean Loss 0.0084\n",
    "2022-05-02 16:12:53,450 - root - INFO - KG Training: Epoch 0010 Iter 2704 / 2719 | Time 0.2s | Iter Loss 0.0062 | Iter Mean Loss 0.0084\n",
    "2022-05-02 16:12:53,638 - root - INFO - KG Training: Epoch 0010 Iter 2705 / 2719 | Time 0.2s | Iter Loss 0.0141 | Iter Mean Loss 0.0084\n",
    "2022-05-02 16:12:53,828 - root - INFO - KG Training: Epoch 0010 Iter 2706 / 2719 | Time 0.2s | Iter Loss 0.0152 | Iter Mean Loss 0.0084\n",
    "2022-05-02 16:12:54,008 - root - INFO - KG Training: Epoch 0010 Iter 2707 / 2719 | Time 0.2s | Iter Loss 0.0080 | Iter Mean Loss 0.0084\n",
    "2022-05-02 16:12:54,196 - root - INFO - KG Training: Epoch 0010 Iter 2708 / 2719 | Time 0.2s | Iter Loss 0.0088 | Iter Mean Loss 0.0084\n",
    "2022-05-02 16:12:54,384 - root - INFO - KG Training: Epoch 0010 Iter 2709 / 2719 | Time 0.2s | Iter Loss 0.0087 | Iter Mean Loss 0.0084\n",
    "2022-05-02 16:12:54,576 - root - INFO - KG Training: Epoch 0010 Iter 2710 / 2719 | Time 0.2s | Iter Loss 0.0072 | Iter Mean Loss 0.0084\n",
    "2022-05-02 16:12:54,762 - root - INFO - KG Training: Epoch 0010 Iter 2711 / 2719 | Time 0.2s | Iter Loss 0.0083 | Iter Mean Loss 0.0084\n",
    "2022-05-02 16:12:54,952 - root - INFO - KG Training: Epoch 0010 Iter 2712 / 2719 | Time 0.2s | Iter Loss 0.0085 | Iter Mean Loss 0.0084\n",
    "2022-05-02 16:12:55,141 - root - INFO - KG Training: Epoch 0010 Iter 2713 / 2719 | Time 0.2s | Iter Loss 0.0062 | Iter Mean Loss 0.0084\n",
    "2022-05-02 16:12:55,322 - root - INFO - KG Training: Epoch 0010 Iter 2714 / 2719 | Time 0.2s | Iter Loss 0.0036 | Iter Mean Loss 0.0084\n",
    "2022-05-02 16:12:55,506 - root - INFO - KG Training: Epoch 0010 Iter 2715 / 2719 | Time 0.2s | Iter Loss 0.0061 | Iter Mean Loss 0.0084\n",
    "2022-05-02 16:12:55,700 - root - INFO - KG Training: Epoch 0010 Iter 2716 / 2719 | Time 0.2s | Iter Loss 0.0071 | Iter Mean Loss 0.0084\n",
    "2022-05-02 16:12:55,882 - root - INFO - KG Training: Epoch 0010 Iter 2717 / 2719 | Time 0.2s | Iter Loss 0.0063 | Iter Mean Loss 0.0084\n",
    "2022-05-02 16:12:56,073 - root - INFO - KG Training: Epoch 0010 Iter 2718 / 2719 | Time 0.2s | Iter Loss 0.0049 | Iter Mean Loss 0.0084\n",
    "2022-05-02 16:12:56,262 - root - INFO - KG Training: Epoch 0010 Iter 2719 / 2719 | Time 0.2s | Iter Loss 0.0042 | Iter Mean Loss 0.0084\n",
    "2022-05-02 16:12:56,262 - root - INFO - KG Training: Epoch 0010 Total Iter 2719 | Total Time 519.8s | Iter Mean Loss 0.0084\n",
    "2022-05-02 16:13:00,256 - root - INFO - Update Attention: Epoch 0010 | Total Time 4.0s\n",
    "2022-05-02 16:13:00,256 - root - INFO - CF + KG Training: Epoch 0010 | Total Time 6192.1s\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compared with NFM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python main_nfm.py --data_name amazon-book"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "2022-06-06 16:29:29,278 - root - INFO - CF Training: Epoch 0010 Iter 0619 / 0638 | Time 0.2s | Iter Loss 0.0144 | Iter Mean Loss 0.0140\n",
    "2022-06-06 16:29:29,488 - root - INFO - CF Training: Epoch 0010 Iter 0620 / 0638 | Time 0.2s | Iter Loss 0.0138 | Iter Mean Loss 0.0140\n",
    "2022-06-06 16:29:29,694 - root - INFO - CF Training: Epoch 0010 Iter 0621 / 0638 | Time 0.2s | Iter Loss 0.0137 | Iter Mean Loss 0.0140\n",
    "2022-06-06 16:29:29,904 - root - INFO - CF Training: Epoch 0010 Iter 0622 / 0638 | Time 0.2s | Iter Loss 0.0136 | Iter Mean Loss 0.0140\n",
    "2022-06-06 16:29:30,103 - root - INFO - CF Training: Epoch 0010 Iter 0623 / 0638 | Time 0.2s | Iter Loss 0.0106 | Iter Mean Loss 0.0140\n",
    "2022-06-06 16:29:30,309 - root - INFO - CF Training: Epoch 0010 Iter 0624 / 0638 | Time 0.2s | Iter Loss 0.0100 | Iter Mean Loss 0.0140\n",
    "2022-06-06 16:29:30,516 - root - INFO - CF Training: Epoch 0010 Iter 0625 / 0638 | Time 0.2s | Iter Loss 0.0186 | Iter Mean Loss 0.0140\n",
    "2022-06-06 16:29:30,719 - root - INFO - CF Training: Epoch 0010 Iter 0626 / 0638 | Time 0.2s | Iter Loss 0.0087 | Iter Mean Loss 0.0140\n",
    "2022-06-06 16:29:30,930 - root - INFO - CF Training: Epoch 0010 Iter 0627 / 0638 | Time 0.2s | Iter Loss 0.0138 | Iter Mean Loss 0.0140\n",
    "2022-06-06 16:29:31,118 - root - INFO - CF Training: Epoch 0010 Iter 0628 / 0638 | Time 0.2s | Iter Loss 0.0251 | Iter Mean Loss 0.0140\n",
    "2022-06-06 16:29:31,313 - root - INFO - CF Training: Epoch 0010 Iter 0629 / 0638 | Time 0.2s | Iter Loss 0.0057 | Iter Mean Loss 0.0140\n",
    "2022-06-06 16:29:31,511 - root - INFO - CF Training: Epoch 0010 Iter 0630 / 0638 | Time 0.2s | Iter Loss 0.0130 | Iter Mean Loss 0.0140\n",
    "2022-06-06 16:29:31,710 - root - INFO - CF Training: Epoch 0010 Iter 0631 / 0638 | Time 0.2s | Iter Loss 0.0094 | Iter Mean Loss 0.0140\n",
    "2022-06-06 16:29:31,905 - root - INFO - CF Training: Epoch 0010 Iter 0632 / 0638 | Time 0.2s | Iter Loss 0.0129 | Iter Mean Loss 0.0140\n",
    "2022-06-06 16:29:32,094 - root - INFO - CF Training: Epoch 0010 Iter 0633 / 0638 | Time 0.2s | Iter Loss 0.0139 | Iter Mean Loss 0.0140\n",
    "2022-06-06 16:29:32,291 - root - INFO - CF Training: Epoch 0010 Iter 0634 / 0638 | Time 0.2s | Iter Loss 0.0099 | Iter Mean Loss 0.0140\n",
    "2022-06-06 16:29:32,490 - root - INFO - CF Training: Epoch 0010 Iter 0635 / 0638 | Time 0.2s | Iter Loss 0.0162 | Iter Mean Loss 0.0140\n",
    "2022-06-06 16:29:32,692 - root - INFO - CF Training: Epoch 0010 Iter 0636 / 0638 | Time 0.2s | Iter Loss 0.0068 | Iter Mean Loss 0.0139\n",
    "2022-06-06 16:29:32,894 - root - INFO - CF Training: Epoch 0010 Iter 0637 / 0638 | Time 0.2s | Iter Loss 0.0088 | Iter Mean Loss 0.0139\n",
    "2022-06-06 16:29:33,091 - root - INFO - CF Training: Epoch 0010 Iter 0638 / 0638 | Time 0.2s | Iter Loss 0.0117 | Iter Mean Loss 0.0139\n",
    "2022-06-06 16:29:33,091 - root - INFO - CF Training: Epoch 0010 Total Iter 0638 | Total Time 137.1s | Iter Mean Loss 0.0139\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python main_nfm.py --data_name last-fm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "2022-06-10 23:33:16,313 - root - INFO - CF Training: Epoch 0010 Iter 1240 / 1259 | Time 0.2s | Iter Loss 0.0140 | Iter Mean Loss 0.0150\n",
    "2022-06-10 23:33:16,470 - root - INFO - CF Training: Epoch 0010 Iter 1241 / 1259 | Time 0.2s | Iter Loss 0.0120 | Iter Mean Loss 0.0150\n",
    "2022-06-10 23:33:16,627 - root - INFO - CF Training: Epoch 0010 Iter 1242 / 1259 | Time 0.2s | Iter Loss 0.0136 | Iter Mean Loss 0.0150\n",
    "2022-06-10 23:33:16,790 - root - INFO - CF Training: Epoch 0010 Iter 1243 / 1259 | Time 0.2s | Iter Loss 0.0217 | Iter Mean Loss 0.0150\n",
    "2022-06-10 23:33:16,955 - root - INFO - CF Training: Epoch 0010 Iter 1244 / 1259 | Time 0.2s | Iter Loss 0.0062 | Iter Mean Loss 0.0150\n",
    "2022-06-10 23:33:17,122 - root - INFO - CF Training: Epoch 0010 Iter 1245 / 1259 | Time 0.2s | Iter Loss 0.0098 | Iter Mean Loss 0.0149\n",
    "2022-06-10 23:33:17,282 - root - INFO - CF Training: Epoch 0010 Iter 1246 / 1259 | Time 0.2s | Iter Loss 0.0112 | Iter Mean Loss 0.0149\n",
    "2022-06-10 23:33:17,440 - root - INFO - CF Training: Epoch 0010 Iter 1247 / 1259 | Time 0.2s | Iter Loss 0.0077 | Iter Mean Loss 0.0149\n",
    "2022-06-10 23:33:17,608 - root - INFO - CF Training: Epoch 0010 Iter 1248 / 1259 | Time 0.2s | Iter Loss 0.0109 | Iter Mean Loss 0.0149\n",
    "2022-06-10 23:33:17,767 - root - INFO - CF Training: Epoch 0010 Iter 1249 / 1259 | Time 0.2s | Iter Loss 0.0169 | Iter Mean Loss 0.0149\n",
    "2022-06-10 23:33:17,928 - root - INFO - CF Training: Epoch 0010 Iter 1250 / 1259 | Time 0.2s | Iter Loss 0.0273 | Iter Mean Loss 0.0149\n",
    "2022-06-10 23:33:18,102 - root - INFO - CF Training: Epoch 0010 Iter 1251 / 1259 | Time 0.2s | Iter Loss 0.0067 | Iter Mean Loss 0.0149\n",
    "2022-06-10 23:33:18,267 - root - INFO - CF Training: Epoch 0010 Iter 1252 / 1259 | Time 0.2s | Iter Loss 0.0117 | Iter Mean Loss 0.0149\n",
    "2022-06-10 23:33:18,427 - root - INFO - CF Training: Epoch 0010 Iter 1253 / 1259 | Time 0.2s | Iter Loss 0.0046 | Iter Mean Loss 0.0149\n",
    "2022-06-10 23:33:18,582 - root - INFO - CF Training: Epoch 0010 Iter 1254 / 1259 | Time 0.2s | Iter Loss 0.0180 | Iter Mean Loss 0.0149\n",
    "2022-06-10 23:33:18,747 - root - INFO - CF Training: Epoch 0010 Iter 1255 / 1259 | Time 0.2s | Iter Loss 0.0192 | Iter Mean Loss 0.0149\n",
    "2022-06-10 23:33:18,904 - root - INFO - CF Training: Epoch 0010 Iter 1256 / 1259 | Time 0.2s | Iter Loss 0.0239 | Iter Mean Loss 0.0149\n",
    "2022-06-10 23:33:19,065 - root - INFO - CF Training: Epoch 0010 Iter 1257 / 1259 | Time 0.2s | Iter Loss 0.0105 | Iter Mean Loss 0.0149\n",
    "2022-06-10 23:33:19,230 - root - INFO - CF Training: Epoch 0010 Iter 1258 / 1259 | Time 0.2s | Iter Loss 0.0132 | Iter Mean Loss 0.0149\n",
    "2022-06-10 23:33:19,396 - root - INFO - CF Training: Epoch 0010 Iter 1259 / 1259 | Time 0.2s | Iter Loss 0.0201 | Iter Mean Loss 0.0149\n",
    "2022-06-10 23:33:19,396 - root - INFO - CF Training: Epoch 0010 Total Iter 1259 | Total Time 207.5s | Iter Mean Loss 0.0149\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python main_nfm.py --data_name yelp2018"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "2022-06-11 12:07:09,607 - root - INFO - CF Training: Epoch 0010 Iter 0890 / 0909 | Time 0.2s | Iter Loss 0.0166 | Iter Mean Loss 0.0154\n",
    "2022-06-11 12:07:09,813 - root - INFO - CF Training: Epoch 0010 Iter 0891 / 0909 | Time 0.2s | Iter Loss 0.0095 | Iter Mean Loss 0.0154\n",
    "2022-06-11 12:07:10,021 - root - INFO - CF Training: Epoch 0010 Iter 0892 / 0909 | Time 0.2s | Iter Loss 0.0240 | Iter Mean Loss 0.0154\n",
    "2022-06-11 12:07:10,226 - root - INFO - CF Training: Epoch 0010 Iter 0893 / 0909 | Time 0.2s | Iter Loss 0.0135 | Iter Mean Loss 0.0154\n",
    "2022-06-11 12:07:10,431 - root - INFO - CF Training: Epoch 0010 Iter 0894 / 0909 | Time 0.2s | Iter Loss 0.0137 | Iter Mean Loss 0.0154\n",
    "2022-06-11 12:07:10,633 - root - INFO - CF Training: Epoch 0010 Iter 0895 / 0909 | Time 0.2s | Iter Loss 0.0148 | Iter Mean Loss 0.0154\n",
    "2022-06-11 12:07:10,842 - root - INFO - CF Training: Epoch 0010 Iter 0896 / 0909 | Time 0.2s | Iter Loss 0.0073 | Iter Mean Loss 0.0154\n",
    "2022-06-11 12:07:11,048 - root - INFO - CF Training: Epoch 0010 Iter 0897 / 0909 | Time 0.2s | Iter Loss 0.0113 | Iter Mean Loss 0.0154\n",
    "2022-06-11 12:07:11,258 - root - INFO - CF Training: Epoch 0010 Iter 0898 / 0909 | Time 0.2s | Iter Loss 0.0107 | Iter Mean Loss 0.0154\n",
    "2022-06-11 12:07:11,464 - root - INFO - CF Training: Epoch 0010 Iter 0899 / 0909 | Time 0.2s | Iter Loss 0.0224 | Iter Mean Loss 0.0154\n",
    "2022-06-11 12:07:11,673 - root - INFO - CF Training: Epoch 0010 Iter 0900 / 0909 | Time 0.2s | Iter Loss 0.0123 | Iter Mean Loss 0.0154\n",
    "2022-06-11 12:07:11,880 - root - INFO - CF Training: Epoch 0010 Iter 0901 / 0909 | Time 0.2s | Iter Loss 0.0171 | Iter Mean Loss 0.0154\n",
    "2022-06-11 12:07:12,089 - root - INFO - CF Training: Epoch 0010 Iter 0902 / 0909 | Time 0.2s | Iter Loss 0.0226 | Iter Mean Loss 0.0154\n",
    "2022-06-11 12:07:12,305 - root - INFO - CF Training: Epoch 0010 Iter 0903 / 0909 | Time 0.2s | Iter Loss 0.0068 | Iter Mean Loss 0.0154\n",
    "2022-06-11 12:07:12,514 - root - INFO - CF Training: Epoch 0010 Iter 0904 / 0909 | Time 0.2s | Iter Loss 0.0135 | Iter Mean Loss 0.0154\n",
    "2022-06-11 12:07:12,723 - root - INFO - CF Training: Epoch 0010 Iter 0905 / 0909 | Time 0.2s | Iter Loss 0.0067 | Iter Mean Loss 0.0154\n",
    "2022-06-11 12:07:12,924 - root - INFO - CF Training: Epoch 0010 Iter 0906 / 0909 | Time 0.2s | Iter Loss 0.0121 | Iter Mean Loss 0.0154\n",
    "2022-06-11 12:07:13,127 - root - INFO - CF Training: Epoch 0010 Iter 0907 / 0909 | Time 0.2s | Iter Loss 0.0115 | Iter Mean Loss 0.0154\n",
    "2022-06-11 12:07:13,341 - root - INFO - CF Training: Epoch 0010 Iter 0908 / 0909 | Time 0.2s | Iter Loss 0.0140 | Iter Mean Loss 0.0154\n",
    "2022-06-11 12:07:13,547 - root - INFO - CF Training: Epoch 0010 Iter 0909 / 0909 | Time 0.2s | Iter Loss 0.0125 | Iter Mean Loss 0.0154\n",
    "2022-06-11 12:07:13,548 - root - INFO - CF Training: Epoch 0010 Total Iter 0909 | Total Time 189.4s | Iter Mean Loss 0.0154\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "759119ed9d539a610393f7447b26ef363725b13b2078354d9d855b97d78b4fc5"
  },
  "kernelspec": {
   "display_name": "Python 3.7.13 ('kgat-pytorch')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
